## Reference:
   1. https://github.com/diegolnasc/kubernetes-best-practices
   2. https://ymmt2005.hatenablog.com/entry/k8s-things
   3. https://medium.com/bb-tutorials-and-thoughts/practice-enough-with-these-questions-for-the-ckad-exam-2f42d1228552
   4. https://www.knowledgehut.com/interview-questions/kubernetes
   5. 
## How do Pods communicate in Kubernetes?
👉 In Kubernetes, each Pod has an IP address. A Pod can communicate with another Pod by directly addressing its IP address, but the recommended way is to use Services. A Service is a set of Pods, which can be reached by a single, fixed DNS name or IP address.

**Step1**: Create the Pod and give it a label - The Pod is usually created through another object like a Deployment, a StatefulSet, or, in OpenShift, a DeploymentConfig. The Pod is assigned a the label in its JSON or YAML, like app: api.

**step2**: Create a Service which selects the backend Pod - A Service is created which selects all Pods that match the given label. This is done by specifying a selector in the Service definition. In this example, the Service is called my-api and it selects Pods with the label app=api.

**Step3**: The app communicates with the backend using the service name as the hostname - The app can now address the API using the Service name as the hostname. So if the app talks to the backend over HTTP then it would look like http://my-api:8080.

![image](https://user-images.githubusercontent.com/33947539/148223276-147c8042-a5cb-4b2e-b9ad-952f69ad255b.png)

If the Pods die, or they need to be restarted, this won’t affect the app, because it will still communicate with the API pods via the Service, which has a stable IP address.

##  How do containers in the same Pod communicate?

Multiple containers in the same Pod share the same IP address. They can communicate with each other by addressing localhost. For example, if a container in a Pod wants to reach another container in the same Pod on port 8080, it can use the address localhost:8080.

Because multi-container Pods share the same IP address and communicate on localhost, this means that two containers can’t share the same port, if they’re in the same Pod.

##  what's the difference between Deployment and Replica set?
>Both replica set and deployment have the attribute replica: 3, what's the difference between deployment and replica set? Does deployment work via replica set under the hood?
![image](https://user-images.githubusercontent.com/33947539/153546341-1ef1f656-c8f5-432e-a1e8-d31cec0f8478.png)

**Answer:** 

A deployment is a higher abstraction that manages one or more replicasets to provide controlled rollout of a new version.

Lets say you use ReplicaSet-A for controlling your pods, then You wish to update your pods to a newer version, now you should create Replicaset-B, scale down ReplicaSet-A and scale up ReplicaSet-B by one step repeatedly (This process is known as rolling update). Although this does the job, but it's not a good practice and it's better to let K8S do the job.

A Deployment resource does this automatically without any human interaction and increases the abstraction by one level.

Note: Deployment doesn't interact with pods directly, it just does rolling update using ReplicaSets.

## What happens when the Kubernetes master fails?

Kubernetes cluster without a master is like a company running without a Manager.

No one else can instruct the workers(k8s components) other than the Manager(master node)
(even you, the owner of the cluster, can only instruct the Manager)

Everything works as usual. Until the work is finished or something stopped them.(because the master node died after assigning the works)

As there is no Manager to re-assign any work for them, the workers will wait and wait until the Manager comes back.

The best practice is to assign multiple managers(master) to your cluster.

## Explain the value and benefits of container orchestration ?

It's important to have an understanding of Kubernetes capabilities around self-healing, automated scheduling, rollouts, and rollbacks

## What is the difference between deploying an application on hosts versus containers?
Be prepared to talk about the value of [containers and] Kubernetes in terms of speed, efficiency, and reliability

## How do you load balance in Kubernetes?

## How do you automate in Kubernetes?

## How do you scale a Kubernetes cluster?
https://github.com/MeSabya/Kubernetes/tree/main/AutoScaling

## Can you explain the different uses for deployments, ReplicaSets, StatefulSets, pods, CronJobs?

## How does Kubernetes handle persistence?

## When would you use something like a ConfigMap or a secret?

## What is a pod affinity used for?

## Can you give an example of when to use an Init Container?

## What is a sidecar container? Can you give a use case for why you would use one?

## Explain to me why you’d suggest that a company build their own Kubernetes cluster in the cloud versus using a managed service ?
https://www.magalix.com/blog/provider-managed-vs.-self-managed-kubernetes

## What are Istio and Linkerd?

## matchLabels, labels, and selectors explained in detail?

```yaml
kind: Deployment
...
metadata:
  name: nginx
  labels:
    app: nginx
    tier: backend
spec:
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
        tier: backend
...
```
### metadata labels 
The first metadata describes the deployment itself. 
It gives a label for that actual deployment. So, if you want to delete that deployment, you would say kubectl delete -l app=nginx,tier=backend. 

### template 
The template is actually a podTemplate. It describes a pod that is launched. One of the fields for the pod templates is replicas. If we set replicas to 2, it would make 2 pods for that deployment, and the deployment would entail both of those pods. So, that template for the pod has a label. So, this isn’t a label for the deployment anymore, it’s a label for the pod that the deployment is deploying.

### matchLabels
we have to tell the deployment to match the pods that it’s deploying. Why doesn’t the deployment automatically match the pod it’s deploying? I have no idea.
*the selector: matchLabels tells the resource, whatever it may be, service, deployment, etc, to match the pod, according to that label.*

Only Job, Deployment, Replica Set, and Daemon Set support matchLabels.

## Difference between targetPort and port in Kubernetes Service definition?

```yaml
kind: Service
apiVersion: v1
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
  - protocol: TCP
    port: 80
    targetPort: 9376
```
What is the difference between the port and targetPort?

**nodePort**: The port on the node where external traffic will come in on

**port**: The port of this service, Some times your application inside container serves different services on a different port.

**targetPort**: This is the actual port on which your application is running inside the container.

### Example: 
The actual application can run 8080 and health checks for this application can run on 8089 port of the container. So if you hit the service without port it doesn't know to which port of the container it should redirect the request. Service needs to have a mapping so that it can hit the specific port of the container.

```yaml
kind: Service
apiVersion: v1
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
    - name: http
      nodePort: 30475
      port: 8089
      protocol: TCP
      targetPort: 8080
    - name: metrics
      nodePort: 31261
      port: 5555
      protocol: TCP
      targetPort: 5555
    - name: health
      nodePort: 30013
      port: 8443
      protocol: TCP
      targetPort: 8085
```
*if you hit the my-service:8089 the traffic is routed to 8080 of the container(targetPort). Similarly, if you hit my-service:8443 then it is redirected to 8085 of the container(targetPort). But this myservice:8089 is internal to the kubernetes cluster and can be used when one application wants to communicate with another application. So to hit the service from outside the cluster someone needs to expose the port on the host machine on which kubernetes is running so that the traffic is redirected to a port of the container. This is node port(port exposed on the host machine). From the above example, you can hit the service from outside the cluster(Postman or any rest-client) by host_ip:nodePort

Say your host machine ip is 10.10.20.20 you can hit the http, metrics, health services by 10.10.20.20:30475, 10.10.20.20:31261, 10.10.20.20:30013.*

## Difference between Container port and targetport in Kubernetes?
In a nutshell: targetPort and containerPort basically refer to the same port (so if both are used they are expected to have the same value) but they are used in two different contexts and have entirely different purposes.

They cannot be used interchangeably as both are part of the specification of two distinct kubernetes resources/objects: Service and Pod respectively. While the purpose of containerPort can be treated as purely informational, targetPort is required by the Service which exposes a set of Pods.

It's important to understand that by declaring containerPort with the specific value in your Pod/Deployment specification you cannot make your Pod to expose this specific port e.g. if you declare in containerPort field that your nginx Pod exposes port 8080 instead of default 80, you still need to configure your nginx server in your container to listen on this port.

Declaring containerPort in Pod specification is optional. Even without it your Service will know where to direct the request based on the info it has declared in its targetPort.

It's good to remember that it's not required to declare targetPort in the Service definition. If you omit it, it defaults to the value you declared for port (which is the port of the Service itself).

## EKS Vs Openshift ..
Both EKS and OpenShift require knowledge of Kubernetes. OpenShift’s GUI makes is very well done and allows newer developers to start to understand different aspects of Kubernetes much easier. EKS simply deploys a control plane for you and requires you to administer and configure your K8 cluster appropriately.

If your enterprise has a need to run/deploy applications both in the cloud and on-prem then OpenShift gives you the flexibility to do this. For small development teams, EKS is probably overkill and look at ECS/Fargate first.

## What is a headless service, what does it do/accomplish, and what are some legitimate use cases for it?
[Answer click me](https://github.com/MeSabya/Kubernetes/blob/main/HeadlessService.md#what-is-a-headless-service-what-does-it-doaccomplish-and-what-are-some-legitimate-use-cases-for-it)

## Kubernetes NodePort vs LoadBalancer vs Ingress? When should I use what?

### ClusterIP
- A ClusterIP service is the default Kubernetes service. It gives you a service inside your cluster that other apps inside your cluster can access. There is no external access.
- If you can’t access a ClusterIP service from the internet, why am I talking about it? Turns out you can access it using the Kubernetes proxy!

![image](https://user-images.githubusercontent.com/33947539/155500939-16a70ef2-e47b-4077-a736-635364ec24bd.png)

There are a few scenarios where you would use the Kubernetes proxy to access your services.

        Debugging your services, or connecting to them directly from your laptop for some reason
        Allowing internal traffic, displaying internal dashboards, etc.

Because this method requires you to run kubectl as an authenticated user, you should NOT use this to expose your service to the internet or use it for production services.

### NodePort
A NodePort service is the most primitive way to get external traffic directly to your service. NodePort, as the name implies, opens a specific port on all the Nodes (the VMs), and any traffic that is sent to this port is forwarded to the service.

![image](https://user-images.githubusercontent.com/33947539/155501278-851ec05b-5841-4692-aded-9da5c9260e3e.png)

![image](https://user-images.githubusercontent.com/33947539/158848421-b9d834ae-95f9-478b-9b3a-ac63081cebdc.png)



#### There are many downsides to this method:
- You can only have one service per port
- You can only use ports 30000–32767
- If your Node/VM IP address change, you need to deal with that


### LoadBalancer
If you want to directly expose a service, this is the default method. All traffic on the port you specify will be forwarded to the service. There is no filtering, no routing, etc. This means you can send almost any kind of traffic to it, like HTTP, TCP, UDP, Websockets, gRPC, or whatever.

![image](https://user-images.githubusercontent.com/33947539/155501631-bcf45795-96f8-49b9-ac50-ee5a731aefaa.png)

The big downside is that each service you expose with a LoadBalancer will get its own IP address, and you have to pay for a LoadBalancer per exposed service, which can get expensive!

### Ingress 

Unlike all the above examples, Ingress is actually NOT a type of service. Instead, it sits in front of multiple services and act as a “smart router” or entrypoint into your cluster. The default GKE ingress controller will spin up a HTTP(S) Load Balancer for you. This will let you do both path based and subdomain based routing to backend services. For example, you can send everything on foo.yourdomain.com to the foo service, and everything under the yourdomain.com/bar/ path to the bar service.

![image](https://user-images.githubusercontent.com/33947539/155501972-c236dcf7-2156-45d8-a312-983a00697c85.png)

```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: my-ingress
spec:
  backend:
    serviceName: other
    servicePort: 8080
  rules:
  - host: foo.mydomain.com
    http:
      paths:
      - backend:
          serviceName: foo
          servicePort: 8080
  - host: mydomain.com
    http:
      paths:
      - path: /bar/*
        backend:
          serviceName: bar
          servicePort: 8080
```

#### When would you use this?
- Ingress is probably the most powerful way to expose your services, but can also be the most complicated. There are many types of Ingress controllers, from the **Google Cloud  
  Load Balancer, Nginx, Contour, Istio, and more**. 
- There are also plugins for Ingress controllers, like the cert-manager, that can automatically provision SSL certificates for your services.
- Ingress is the most useful if you want to expose multiple services under the same IP address, and these services all use the same L7 protocol (typically HTTP). You only pay  
  for one load balancer if you are using the native GCP integration, and because Ingress is “smart” you can get a lot of features out of the box (like SSL, Auth, Routing, etc)

## Tools Used To Create Or Manage Kubernetes Clusters ?

#### Kubespray
Kubespray provides an Ansible role for Kubernetes deployment and configuration. It can be used on any cloud provider, or on-premises. It uses Kubeadm under the hood.

#### Kubeadm
Kubeadm Bootstrap is a best practice Kubernetes cluster on existing infrastructure. It uses the bare minimum viable Kubernetes cluster possible.

#### Kops
Kops is a tool that can be used to create, delete, upgrade, and maintain production-based highly available Kubernetes clusters. Kops enables you to manage the full Kubernetes cluster lifecycle: from infrastructure, provisioning, to cluster deletion.

#### Kubetail
It is a small bash script used to aggregate logs from multiple pods into one stream.

#### Kubewatch
This tool is a Kubernetes watcher that publishes the Kubernetes event to the team via the communication app, Slack. Kubewatch runs as a pod inside Kubernetes clusters, and watches for changes that occur in the system.

#### Prometheus
Prometheus, a famous tool used for monitoring the cluster. It’s very simple to integrate yet extremely powerful.

#### HELM
HELM is a package manager for Kubernetes. It’s like an npm, pip for Kubernetes. HELM operates on the chart and you can share your application thru HELM chart creation.

#### Istio
Istio is an open-sourced service mesh used to make it easier to connect, manage, and secure traffic. It observes telemetry about microservices running in containers.

#### CoreDNS

#### Kubernetes Dashboard

## What is an 'endpoint' in Kubernetes?

An endpoint is an resource that gets IP addresses of one or more pods dynamically assigned to it, along with a port. An endpoint can be viewed using kubectl get endpoints.

An endpoint resource is referenced by a kubernetes service, so that the service has a record of the internal IPs of pods in order to be able to communicate with them.

We need endpoints as an abstraction layer because the 'service' in kubernetes acts as part of the orchestration to ensure distribution of traffic to pods (including only sending traffic to healthy pods). For example if a pod dies, a replacement pod will be generated, with a new IP address. Conceptually, the dead pod IP will be removed from the endpoint object, and the IP of the newly created pod will be added, so that the service is updated and 'knows' which pods to connect to.

An easy way to investigate and see the relationship is:

- kubectl describe pods - and observe the IP addresses of your pods
- kubectl get ep - and observe the IP addresses assigned to your endpoint
- kubectl describe service myServiceName - and observe the Endpoints associated with your service.

![image](https://user-images.githubusercontent.com/33947539/159294455-8f1d2a1b-166d-4bf9-82b8-c0406162e8bf.png)
