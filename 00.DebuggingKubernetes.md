## References 
1. https://medium.com/@danielepolencic/isolating-kubernetes-pods-for-debugging-5fe41e630e9
2. https://github.com/nicolaka/netshoot

## After applying some changes to the /etc/kubernetes/manifests/kube-apiserver.yaml file, api-server is not responding. kubectl get pods -n kubesystem is throwing error.How to debug this?

If journalctl is not enabled or you are using a system where logs are not managed via systemd, you can use alternative methods to access the logs.

Alternative Ways to View API Server Logs

### 1. Use Docker to Access Logs (If Docker is Used as Container Runtime)
If the Kubernetes components run as Docker containers, you can inspect the logs using Docker.

Command:

```bash
docker ps | grep kube-apiserver
```
Note the container ID for kube-apiserver, then view the logs:

```bash
docker logs <container-id>
```

### 2. Use crictl to Access Logs (If Using containerd)
If containerd is the container runtime, use crictl to access the logs.

```bash
crictl ps | grep kube-apiserver
```
Get the container ID and view the logs:

```bash
crictl logs <container-id>
```

### 3. Directly Inspect Static Pod Logs
Static pods like kube-apiserver log output to /var/log/pods or /var/log/containers on the node where they are running.

Command:

```bash
ls /var/log/pods/kube-system_kube-apiserver*
cat /var/log/pods/kube-system_kube-apiserver*/<log-file>.log
```

### 4. Check kubelet Logs
The kubelet manages the API server pod, and its logs may provide information about why the API server failed.

Command:

```bash
cat /var/log/kubelet.log | grep apiserver
```

### 5. Check System Logs
If logs are not explicitly set up, you can check the default log file locations for kube-apiserver:

```bash
/var/log/kube-apiserver.log
/var/log/syslog (for Debian-based systems):

grep kube-apiserver /var/log/syslog
/var/log/messages (for RHEL-based systems):

grep kube-apiserver /var/log/messages
```
