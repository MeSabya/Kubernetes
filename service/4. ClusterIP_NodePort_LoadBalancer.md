## NodePorts

Expose a public port on your worker node and use the public IP address of the worker node to access your service in the cluster publicly from the internet.

When you expose your app by creating a Kubernetes service of type NodePort, a NodePort in the range of 30000 - 32767 and an internal cluster IP address is assigned to the service. 

- The NodePort service serves as the external entry point for incoming requests for your app. 
- The assigned NodePort is publicly exposed in the kubeproxy settings of each worker node in the cluster. 
- Every worker node starts listening on the assigned NodePort for incoming requests for the service. 

- To access the service from the internet, you can use the public IP address of any worker node that was assigned during cluster creation and the NodePort in the format <IP_address>:<nodeport>. If you want to access the service on the private network, use the private IP address of any worker node instead of the public IP address.

The following diagram shows how communication is directed from the internet to an app when a NodePort service is configured.

![image](https://user-images.githubusercontent.com/33947539/203693902-3bb6291d-a5c6-4477-aa12-e1feee0c9cd9.png)

- A request is sent to your app by using the public IP address of your worker node and the NodePort on the worker node.
- The request is automatically forwarded to the NodePort service's internal cluster IP address and port. The internal cluster IP address is accessible inside the cluster only.
- kube-proxy routes the request to the Kubernetes NodePort service for the app.
- The request is forwarded to the private IP address of the pod where the app is deployed. If multiple app instances are deployed in the cluster, the NodePort service routes the requests between the app pods.

*The public IP address of the worker node is not permanent. When a worker node is removed or re-created, a new public IP address is assigned to the worker node. 
 You can use the NodePort service for testing the public access for your app or when public access is needed for a short amount of time only. 
  When you require a stable public IP address and more availability for your service, expose your app by using a network load balancer (NLB) service or Ingress.*
  
### Example 

```yaml
apiVersion: v1
kind: Service
metadata:
  name: <my-nodeport-service>
  labels:
    <my-label-key>: <my-label-value>
spec:
  selector:
    <my-selector-key>: <my-selector-value>
  type: NodePort
  ports:
   - port: <8081>
     # nodePort: <31514>
 ```
 
#### Component	Description

1. name	Replace <my-nodeport-service> with a name for your NodePort service. Learn more about securing your personal information when you work with Kubernetes resources.

2. labels	Replace <my-label-key> and <my-label-value> with the label that you want to use for your service.

3. selector	Replace <my-selector-key> and <my-selector-value> with the key/value pair that you used in the spec.template.metadata.labels section of your deployment YAML. To associate the service with the deployment, the selector must match the deployment labels.

4. port	Replace <8081> with the port that your service listens on.

5. nodePort	Optional: Replace <31514> with a NodePort in the 30000 - 32767 range. Do not specify a NodePort that is already in use by another service. 
   
   ***If no NodePort is assigned, a random one is assigned for you.***
   To specify a NodePort and see which NodePorts are already in use, run the kubectl get svc command. Any NodePorts in use appear under the Ports field.     
      
When the app is deployed, you can use the public IP address of any worker node and the NodePort to form the public URL to access the app in a browser.      

## How to expose multiple port in services in kubernetes or Multi-Port Services

Kubernetes lets you configure multiple port definitions on a Service object. When using multiple ports for a Service, you must give all of your ports names so that these are unambiguous. For example:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 9376
    - name: https
      protocol: TCP
      port: 443
      targetPort: 9377     
```    

### Drawbacks
NodePorts are a convenient addressing mechanism, especially in dev/test; but have significant downsides in comparison to ingress:

- Clients are expected to know node IP addresses to reach the service.  In contrast, Ingress makes it easier to use a DNS entry, and hiding cluster internals such as  
  the number of nodes and their IP addresses

- NodePort requires opening up external port access to every node in the cluster for each service, which increases the complexity of securely managing the cluster – a 
  cluster with more than a handful of services will look like a block of swiss cheese in terms of the number of holes into that cluster


## Load Balancers
Load balancers have different characteristics from ingresses. Rather than a standalone object like an ingress, a load balancer is just an extension of a service.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: api-service
spec:
  selector:
    app: api-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
  type: LoadBalancer     
```
For this to work, the cluster must be running on a provider that supports external load balancers. All of the major cloud providers support external load balancers using their own resource types:

- AWS uses a Network Load Balancer
- GKE also uses a Network Load Balancer
- Azure uses a Public Load Balancer     

Because load balancers are defined per service, they can only route to a single service. This is different from an ingress, which has the ability to route to multiple services inside the cluster.

Also, keep in mind that regardless of the provider, using an external load balancer will typically come with additional costs.     

What you can’t do using this type is to use a host or path-based routings. 
     
#### Load Balancer :Here my thoughts about this service type:

- If you have the possibility to use this type of service, go fo it.
- All traffic on the port you specify will be forwarded to the service. There is no filtering, no routing, etc.
- The big downside of it is that it is usually only available on a Cloud environment where you have to pay to allocate a Load Balancer for your service.
- You have an IP for each service.
- It’s expensive.

## Ingress
It has the following capabilities:
     
1. content-based routing, e.g., routing based on HTTP method, request headers, or other properties of the specific request
2. resilience, e.g., rate limiting, timeouts
3. support for multiple protocols, e.g., WebSockets or gRPC
4. authentication     
     
##### Read more on: https://platform9.com/blog/ultimate-guide-to-kubernetes-ingress-controllers/     
     
     
